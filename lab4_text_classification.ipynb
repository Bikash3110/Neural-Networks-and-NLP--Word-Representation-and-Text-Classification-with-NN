{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lab4_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hExKCzh6doIW"
      },
      "source": [
        "# Lab 4 - Neural Network Classifier Using Simple Word Embeddings\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HixoFOoCIJ7V"
      },
      "source": [
        "In this session, we demonstrate how to solve a text classification task using simple \n",
        "feedforward neural network classifier. We will use IMDB Large Movie Review Dataset to train a binary classification model, able to predict whether a review is positive or negative. First, our network takes one-hot word vectors as input, averages them to make one vector and trains a \n",
        "fully-connected layer to predict the output. In the second part, we replace the one-hot vectors with the word embeddings and add a layer to see how much that improves the performance.\n",
        "\n",
        "We are going to use Keras Sequential API in this session. The Sequential API allows you to make models layer-by-layer. But it is not straightforward to define models where layers connect to more than just the previous and next layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8fpBfhBpupy",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cqvPQvgvPv1W"
      },
      "source": [
        "### Downloading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EundMtGPpCdf"
      },
      "source": [
        "The dataset we will be using is the IMDB Large Movie Review Dataset, which consists of 50000 labeled movie reviews. These are split into 25,000 reviews for training and 25,000 reviews for testing. The  dataset contains an even number of positive and negative reviews, so randomly guessing yields 50% accuracy. The data is preprocessed. For text classification, it is ususal to limit the size of the vocabulary to stop the dataset from becoming too sparse, creating possible overfitting. We keep the top 10,000 most frequently occurring words in the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NyuSzkafqNca",
        "colab": {}
      },
      "source": [
        "imdb = keras.datasets.imdb\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6U4iCV9-rmay"
      },
      "source": [
        "We now can start playing around with the data, letâ€™s first see the length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h-gjWRAuqg5s",
        "outputId": "9ec8ed4f-5393-4add-fd1e-b30abeddbd7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(X_train), len(y_train)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MTRZrpcyr-4x"
      },
      "source": [
        "The  reviews have been converted to integers and each integer represents a  word in a dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "79Ev72Kgq4XL",
        "outputId": "bbec284c-709f-469e-c529-297a7bd6f621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " X_train[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tvuu4KhStqei"
      },
      "source": [
        "We can convert integers back to words by querying a dictionary object that contains the integer to string mapping:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gMCH1OoDrSNR",
        "colab": {}
      },
      "source": [
        "\n",
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5IreFXgruZot"
      },
      "source": [
        "Index 1 represents the beginning of the sentence and the index 2 is assigned to all unknown tokens. Index 0 will be used for padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "abIb7Fe5u3GQ",
        "colab": {}
      },
      "source": [
        "\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  \n",
        "word_index[\"<UNUSED>\"] = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9TnnSuspvC5b"
      },
      "source": [
        "To reverse key and values in a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nKOiVVXQu-_I",
        "colab": {}
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZmTJEm8xvUvW"
      },
      "source": [
        "To view a word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SqN5jgVKvJJZ",
        "outputId": "eb5526dd-8f65-4580-99f6-21f62d72649f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reverse_word_index[25]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q6QjrzgVvrYn"
      },
      "source": [
        "And to recreate the whole sentence from our training data we define decode_review:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wvrKeMgxvWlv",
        "colab": {}
      },
      "source": [
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sxg4YA_NvdRg",
        "outputId": "46cb1e48-1285-4300-b053-7e71f567c7af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "decode_review(X_train[10])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> french horror cinema has seen something of a revival over the last couple of years with great films such as inside and <UNK> romance <UNK> on to the scene <UNK> <UNK> the revival just slightly but stands head and shoulders over most modern horror titles and is surely one of the best french horror films ever made <UNK> was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is <UNK> by the excellent writing and acting that ensure the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named <UNK> sent to prison for fraud he is put in a cell with three others the quietly insane <UNK> body building <UNK> marcus and his retarded boyfriend daisy after a short while in the cell together they stumble upon a hiding place in the wall that contains an old <UNK> after <UNK> part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that <UNK> makes the best of it's <UNK> as despite it's <UNK> the film never actually feels restrained and manages to flow well throughout director eric <UNK> provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell <UNK> that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really <UNK> people and this film proves that as the director <UNK> that we can never really be sure of exactly what is round the corner and this helps to ensure that <UNK> actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall <UNK> is a truly great horror film and one of the best of the decade highly recommended viewing\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c8gIzXncfaJK"
      },
      "source": [
        "### Creating One-hot word vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B9W4yb3rv_E0"
      },
      "source": [
        "It is  common to use one-hot representation as input in Natural Language Processing tasks. In Keras, the Embedding layer takes an index as an input and convert it to one-hot vector with the length of the vocabulary size. Then multiplies these vectors by a normal weight matrix. But there is no way to only get a one-hot vector as the output of a layer in Keras. To solve this we use Lambda() layer and a function that creates the one-hot layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RPO_pK9zH4C5",
        "colab": {}
      },
      "source": [
        "def OneHot(input_dim=None, input_length=None):\n",
        "    \n",
        "    if input_dim is None or input_length is None:\n",
        "        raise TypeError(\"input_dim or input_length is not set\")\n",
        "\n",
        "    \n",
        "    def _one_hot(x, num_classes):\n",
        "        return K.one_hot(K.cast(x, 'uint8'),\n",
        "                          num_classes=num_classes)\n",
        "\n",
        "    return Lambda(_one_hot,\n",
        "                  arguments={'num_classes': input_dim},\n",
        "                  input_shape=(input_length,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "364d3MAw0ez9"
      },
      "source": [
        "input_dim refers to the length of the one-hot vector and input_length refers to the length of the input sequence. Since the input to K.one_hot should be an integer tensor, we cast x to one (Keras passes around float tensors by default).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VHz76GNA2M4r"
      },
      "source": [
        " Each text sequence has in most cases different length of words. Here, we fill sequences with a pad token (0) to fit the size. This special tokens is then masked not to be accounted in averaging, loss calculation etc. We set the maximum length to 256."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9G_o7PsvgSFt"
      },
      "source": [
        "### Preparing input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jiFn7sd_wF5j",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_SEQUENCE_LENGTH = 256\n",
        "\n",
        "X_train_enc = keras.preprocessing.sequence.pad_sequences(X_train,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "X_test_enc = keras.preprocessing.sequence.pad_sequences(X_test,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kcjFH1wKF_7d"
      },
      "source": [
        "And to view a padded review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zwH4dcfW_a18",
        "outputId": "30c28471-e4e8-40ec-98c4-044e7f1acbfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "print(X_train_enc[1])\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1  194 1153  194 8255   78  228    5    6 1463 4369 5012  134   26\n",
            "    4  715    8  118 1634   14  394   20   13  119  954  189  102    5\n",
            "  207  110 3103   21   14   69  188    8   30   23    7    4  249  126\n",
            "   93    4  114    9 2300 1523    5  647    4  116    9   35 8163    4\n",
            "  229    9  340 1322    4  118    9    4  130 4901   19    4 1002    5\n",
            "   89   29  952   46   37    4  455    9   45   43   38 1543 1905  398\n",
            "    4 1649   26 6853    5  163   11 3215    2    4 1153    9  194  775\n",
            "    7 8255    2  349 2637  148  605    2 8003   15  123  125   68    2\n",
            " 6853   15  349  165 4362   98    5    4  228    9   43    2 1157   15\n",
            "  299  120    5  120  174   11  220  175  136   50    9 4373  228 8255\n",
            "    5    2  656  245 2350    5    4 9837  131  152  491   18    2   32\n",
            " 7464 1212   14    9    6  371   78   22  625   64 1382    9    8  168\n",
            "  145   23    4 1690   15   16    4 1355    5   28    6   52  154  462\n",
            "   33   89   78  285   16  145   95    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F1zcxFwNGepA"
      },
      "source": [
        "Now we want to build the neural network model. We  are going to have a hidden layer with 16 hidden units. \n",
        "\n",
        "First, we want to transform each index to an embedded vector and then average all vectors to a single one. It has been showed that unweighted average of word vectors outperforms many complicated networks that model semantic and syntactic compositionality. As an example you can take a look at this: (http://anthology.aclweb.org/P/P15/P15-1162.pdf)\n",
        "\n",
        "To average we need to ignore padded zeros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yi04MLIvJOGZ",
        "colab": {}
      },
      "source": [
        "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
        "    def call(self, x, mask=None):\n",
        "        if mask != None:\n",
        "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
        "        else:\n",
        "            return super().call(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "whgIIB5ggjna"
      },
      "source": [
        "### Neural Network model using one-hot vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jlOLnlnSJgrU"
      },
      "source": [
        "The first layer is an one-hot layer. The second layer is to compute average on all word vectors in a sentence without considering padding. The  output vector is piped through a fully-connected layer. The last layer is connected with a single output node with the sigmoid activation function. The final value is a float between 0 and 1. \n",
        "The vocabulary count of the movie reviews (10000) is used as the input shape. At the end we visualize the model summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Pn83gBbxiK7",
        "colab": {}
      },
      "source": [
        "# put your code here\n",
        "\n",
        "model = Sequential()\n",
        "model.add(OneHot(input_dim = VOCAB_SIZE, input_length = MAX_SEQUENCE_LENGTH))\n",
        "model.add(GlobalAveragePooling1DMasked())\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Mz96xpCgvTj"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F3HbW_IKLqwT"
      },
      "source": [
        "To compile the model we need a loss function and an optimizer. We use binary_crossentropy loss function which is just a special case of categorical cross entropy. We also use Adam optimizer that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. You can read more about it here:\n",
        "(https://arxiv.org/abs/1412.6980v8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qh1PWTNMxjUw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "a4831b67-be5c-4d84-feba-645ca1964039"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_4 (Lambda)            (None, 256, 10000)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_mas (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 10001     \n",
            "=================================================================\n",
            "Total params: 10,001\n",
            "Trainable params: 10,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E1jwQQqCN5Ia"
      },
      "source": [
        "When training, we want to check the accuracy of the model on data it hasn't seen before. So we create a validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f5lAqzQlxjSM",
        "colab": {}
      },
      "source": [
        "X_val = np.array(X_train_enc[:10000])\n",
        "partial_X_train = np.array(X_train_enc[10000:])\n",
        "\n",
        "y_val = np.array(y_train[:10000])\n",
        "partial_y_train = np.array(y_train[10000:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E8Kpo5G3OJEY"
      },
      "source": [
        "Then we start to train the model for 40 epochs in mini-batches of 512 samples and monitor the model's loss and accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "99_z39KAxjPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b08f490-26de-4437-c7c9-c2054f85c5ee"
      },
      "source": [
        "history = model.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 6s 427us/step - loss: 0.6930 - acc: 0.5035 - val_loss: 0.6929 - val_acc: 0.4947\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 6s 404us/step - loss: 0.6926 - acc: 0.5095 - val_loss: 0.6925 - val_acc: 0.5084\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 6s 406us/step - loss: 0.6922 - acc: 0.5486 - val_loss: 0.6921 - val_acc: 0.5439\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 6s 408us/step - loss: 0.6918 - acc: 0.5235 - val_loss: 0.6917 - val_acc: 0.5301\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 6s 409us/step - loss: 0.6913 - acc: 0.5754 - val_loss: 0.6913 - val_acc: 0.6022\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 6s 408us/step - loss: 0.6909 - acc: 0.6305 - val_loss: 0.6910 - val_acc: 0.6042\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 6s 412us/step - loss: 0.6905 - acc: 0.6095 - val_loss: 0.6906 - val_acc: 0.6086\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 6s 412us/step - loss: 0.6901 - acc: 0.6158 - val_loss: 0.6902 - val_acc: 0.6284\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 6s 413us/step - loss: 0.6897 - acc: 0.6540 - val_loss: 0.6898 - val_acc: 0.6520\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 6s 411us/step - loss: 0.6893 - acc: 0.6509 - val_loss: 0.6894 - val_acc: 0.6517\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 6s 410us/step - loss: 0.6889 - acc: 0.6661 - val_loss: 0.6891 - val_acc: 0.6550\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 6s 412us/step - loss: 0.6885 - acc: 0.6539 - val_loss: 0.6887 - val_acc: 0.6487\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 6s 414us/step - loss: 0.6881 - acc: 0.6639 - val_loss: 0.6883 - val_acc: 0.6593\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 6s 413us/step - loss: 0.6877 - acc: 0.6648 - val_loss: 0.6880 - val_acc: 0.6592\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 6s 415us/step - loss: 0.6874 - acc: 0.6667 - val_loss: 0.6876 - val_acc: 0.6594\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6870 - acc: 0.6705 - val_loss: 0.6872 - val_acc: 0.6615\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 6s 415us/step - loss: 0.6866 - acc: 0.6726 - val_loss: 0.6869 - val_acc: 0.6632\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 6s 415us/step - loss: 0.6862 - acc: 0.6676 - val_loss: 0.6866 - val_acc: 0.6602\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 6s 416us/step - loss: 0.6858 - acc: 0.6659 - val_loss: 0.6862 - val_acc: 0.6623\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6854 - acc: 0.6707 - val_loss: 0.6858 - val_acc: 0.6649\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6850 - acc: 0.6728 - val_loss: 0.6855 - val_acc: 0.6646\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 6s 420us/step - loss: 0.6847 - acc: 0.6706 - val_loss: 0.6851 - val_acc: 0.6629\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 6s 419us/step - loss: 0.6843 - acc: 0.6743 - val_loss: 0.6847 - val_acc: 0.6661\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6839 - acc: 0.6742 - val_loss: 0.6844 - val_acc: 0.6653\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 6s 419us/step - loss: 0.6835 - acc: 0.6763 - val_loss: 0.6840 - val_acc: 0.6681\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 6s 419us/step - loss: 0.6832 - acc: 0.6781 - val_loss: 0.6837 - val_acc: 0.6660\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 6s 420us/step - loss: 0.6828 - acc: 0.6792 - val_loss: 0.6833 - val_acc: 0.6673\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 6s 421us/step - loss: 0.6824 - acc: 0.6761 - val_loss: 0.6830 - val_acc: 0.6669\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 6s 420us/step - loss: 0.6820 - acc: 0.6769 - val_loss: 0.6827 - val_acc: 0.6678\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 6s 420us/step - loss: 0.6817 - acc: 0.6761 - val_loss: 0.6824 - val_acc: 0.6680\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 6s 420us/step - loss: 0.6813 - acc: 0.6773 - val_loss: 0.6820 - val_acc: 0.6676\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 6s 421us/step - loss: 0.6809 - acc: 0.6781 - val_loss: 0.6816 - val_acc: 0.6706\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 6s 421us/step - loss: 0.6806 - acc: 0.6796 - val_loss: 0.6813 - val_acc: 0.6703\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 6s 423us/step - loss: 0.6802 - acc: 0.6793 - val_loss: 0.6810 - val_acc: 0.6698\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 6s 423us/step - loss: 0.6798 - acc: 0.6771 - val_loss: 0.6807 - val_acc: 0.6675\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 6s 423us/step - loss: 0.6795 - acc: 0.6793 - val_loss: 0.6803 - val_acc: 0.6703\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 6s 422us/step - loss: 0.6791 - acc: 0.6796 - val_loss: 0.6799 - val_acc: 0.6716\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 6s 422us/step - loss: 0.6788 - acc: 0.6800 - val_loss: 0.6796 - val_acc: 0.6710\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 6s 423us/step - loss: 0.6784 - acc: 0.6798 - val_loss: 0.6792 - val_acc: 0.6713\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 6s 424us/step - loss: 0.6780 - acc: 0.6807 - val_loss: 0.6789 - val_acc: 0.6722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i_9a_rybhG5J"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EYLH8kOgOo9W"
      },
      "source": [
        "To evaulate the model on test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CFMt2Q7b3taP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f40a208-5471-46de-a3a9-11d8e6f95e5c"
      },
      "source": [
        "results = model.evaluate(X_test_enc, y_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 7s 276us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9RrKiPHcAmQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fe0fb71-1271-46f7-f30d-a8cd7b5c7b5c"
      },
      "source": [
        "print(results)\n",
        "# loss, accuracay "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6785520486068726, 0.67244]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pW7IpHxMO6qp"
      },
      "source": [
        "Our first model accuracy using one-hot vectors is \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OwZk_yoWhPJB"
      },
      "source": [
        "### Plotting the accuracy graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JIDPH1J7PMzN"
      },
      "source": [
        "To plot a graph of accuracy and loss over time we can use Matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LS9k2vvSAqB7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "183e5859-c39b-4f50-9c0d-6fbd5c5da11a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTFiWIIwxxoRlCcIYY0xY/w+iP2l526SFEQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a7OwOQw4h8RX"
      },
      "source": [
        "### Neural Network model using word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l-QzOMO_P4jc"
      },
      "source": [
        "Now instead of one-hot vectors, we want to use embedding. We change our first layer in model1 to an Embedding layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MFrCsL-NBFVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "315bc8c8-141c-4d14-cac9-aa209b2b8101"
      },
      "source": [
        "VOCAB_SIZE= 10000\n",
        "\n",
        "# put the code here\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(VOCAB_SIZE , MAX_SEQUENCE_LENGTH))\n",
        "model2.add(GlobalAveragePooling1DMasked())\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# model2 summary\n",
        "model2.summary()\n",
        "\n",
        "\n",
        "X_val = np.array(X_train_enc[:10000])\n",
        "partial_X_train = np.array(X_train_enc[10000:])\n",
        "\n",
        "history2 = model2.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)\n",
        "\n",
        "results = model2.evaluate(X_test_enc, y_test)\n",
        "print(results)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 256)         2560000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_mas (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 2,560,257\n",
            "Trainable params: 2,560,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 65us/step - loss: 0.6874 - acc: 0.6300 - val_loss: 0.6799 - val_acc: 0.7166\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.6674 - acc: 0.7202 - val_loss: 0.6557 - val_acc: 0.7252\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.6346 - acc: 0.7489 - val_loss: 0.6198 - val_acc: 0.7462\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.5923 - acc: 0.7702 - val_loss: 0.5784 - val_acc: 0.7723\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.5460 - acc: 0.7977 - val_loss: 0.5362 - val_acc: 0.7973\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.5007 - acc: 0.8219 - val_loss: 0.4963 - val_acc: 0.8138\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.4593 - acc: 0.8431 - val_loss: 0.4618 - val_acc: 0.8316\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.4232 - acc: 0.8563 - val_loss: 0.4324 - val_acc: 0.8415\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.3923 - acc: 0.8689 - val_loss: 0.4086 - val_acc: 0.8496\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.3666 - acc: 0.8768 - val_loss: 0.3886 - val_acc: 0.8551\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.3440 - acc: 0.8849 - val_loss: 0.3727 - val_acc: 0.8589\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.3245 - acc: 0.8903 - val_loss: 0.3587 - val_acc: 0.8650\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.3075 - acc: 0.8958 - val_loss: 0.3477 - val_acc: 0.8685\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.2926 - acc: 0.9009 - val_loss: 0.3378 - val_acc: 0.8696\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.2786 - acc: 0.9065 - val_loss: 0.3291 - val_acc: 0.8734\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 1s 42us/step - loss: 0.2664 - acc: 0.9097 - val_loss: 0.3222 - val_acc: 0.8762\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.2551 - acc: 0.9141 - val_loss: 0.3166 - val_acc: 0.8769\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.2447 - acc: 0.9183 - val_loss: 0.3115 - val_acc: 0.8773\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.2352 - acc: 0.9219 - val_loss: 0.3063 - val_acc: 0.8796\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.2258 - acc: 0.9259 - val_loss: 0.3025 - val_acc: 0.8802\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.2170 - acc: 0.9290 - val_loss: 0.3002 - val_acc: 0.8803\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.2097 - acc: 0.9329 - val_loss: 0.2971 - val_acc: 0.8815\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.2015 - acc: 0.9355 - val_loss: 0.2942 - val_acc: 0.8831\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1949 - acc: 0.9386 - val_loss: 0.2922 - val_acc: 0.8832\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1882 - acc: 0.9417 - val_loss: 0.2909 - val_acc: 0.8826\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.1818 - acc: 0.9447 - val_loss: 0.2892 - val_acc: 0.8838\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1757 - acc: 0.9475 - val_loss: 0.2883 - val_acc: 0.8841\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1707 - acc: 0.9492 - val_loss: 0.2875 - val_acc: 0.8848\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.1649 - acc: 0.9524 - val_loss: 0.2872 - val_acc: 0.8853\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.1595 - acc: 0.9540 - val_loss: 0.2871 - val_acc: 0.8840\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1547 - acc: 0.9553 - val_loss: 0.2891 - val_acc: 0.8817\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1503 - acc: 0.9576 - val_loss: 0.2872 - val_acc: 0.8854\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1458 - acc: 0.9590 - val_loss: 0.2877 - val_acc: 0.8848\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.1415 - acc: 0.9601 - val_loss: 0.2880 - val_acc: 0.8851\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1370 - acc: 0.9631 - val_loss: 0.2888 - val_acc: 0.8865\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 1s 40us/step - loss: 0.1328 - acc: 0.9649 - val_loss: 0.2901 - val_acc: 0.8854\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1291 - acc: 0.9657 - val_loss: 0.2907 - val_acc: 0.8854\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1257 - acc: 0.9670 - val_loss: 0.2931 - val_acc: 0.8828\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1218 - acc: 0.9686 - val_loss: 0.2926 - val_acc: 0.8835\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 1s 41us/step - loss: 0.1184 - acc: 0.9695 - val_loss: 0.2938 - val_acc: 0.8840\n",
            "25000/25000 [==============================] - 1s 39us/step\n",
            "[0.31058598096847534, 0.8742]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I4zIPJDcTPq3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "567df019-00e4-4590-c2bd-a4aa330e27df"
      },
      "source": [
        "results = model2.evaluate(X_test_enc, y_test)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 39us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "waS96edDTRyL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a7f14f4-3cb2-48c8-fb7d-16556038b50b"
      },
      "source": [
        "print (results)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.31058598096847534, 0.8742]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XB7aveVzTC5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "227502c2-5e91-4379-dbac-82214e9cbe4d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history2.history\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7FBpTc_rXGvQ"
      },
      "source": [
        "The accuracy of model2 is 87%. Using Embedding layer instead of one-hot layer improved the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "--020hfG6rN2"
      },
      "source": [
        "### Using pre-trained word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J4gBeOyi4gkM"
      },
      "source": [
        "The Embedding layer can be used to load a pre-trained word embedding model. We are going to use GloVe embeddings, which you can read about it here (https://nlp.stanford.edu/projects/glove/). GloVe stands for \"Global Vectors for Word Representation\". It's a somewhat popular embedding technique based on factorizing a matrix of word co-occurence statistics. You can download GloVe and we can seed the Keras Embedding layer with weights from the pre-trained embedding for the words in your dataset.\n",
        "First, we need to read GloVe and map words to GloVe:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f_PypdqG9Iis",
        "colab": {}
      },
      "source": [
        "from keras.initializers import Constant\n",
        "\n",
        "def readGloveFile(gloveFile):\n",
        "    with open(gloveFile, 'r') as f:\n",
        "        wordToGlove = {}  \n",
        "        wordToIndex = {}  \n",
        "        indexToWord = {}  \n",
        "\n",
        "        for line in f:\n",
        "            record = line.strip().split()\n",
        "            token = record[0] \n",
        "            wordToGlove[token] = np.array(record[1:], dtype=np.float64) \n",
        "            \n",
        "        tokens = sorted(wordToGlove.keys())\n",
        "        for idx, tok in enumerate(tokens):\n",
        "            kerasIdx = idx + 1  \n",
        "            wordToIndex[tok] = kerasIdx \n",
        "            indexToWord[kerasIdx] = tok \n",
        "\n",
        "    return wordToIndex, indexToWord, wordToGlove"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZcIZ3dq59bCh"
      },
      "source": [
        "Now, we create our pre-trained Embedding layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gembn7VM3ex8",
        "colab": {}
      },
      "source": [
        "def createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable):\n",
        "    vocabLen = len(wordToIndex) + 1  \n",
        "    embDim = next(iter(wordToGlove.values())).shape[0]  \n",
        "   \n",
        "    embeddingMatrix = np.zeros((vocabLen, embDim))  \n",
        "    for word, index in wordToIndex.items():\n",
        "        embeddingMatrix[index, :] = wordToGlove[word] \n",
        "\n",
        "    embeddingLayer = Embedding(vocabLen, embDim, embeddings_initializer=Constant(embeddingMatrix), trainable=isTrainable)\n",
        "    return embeddingLayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HGxciLK4-xOr"
      },
      "source": [
        "We freeze the weights. To create the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PZCPUM0W_Drc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "3ed86b4b-8d98-4429-ad4d-5d3beec83e5a"
      },
      "source": [
        "# put the code here\n",
        "\n",
        "wordToIndex, indexToWord, wordToGlove = readGloveFile('./glove.6B.50d.txt')\n",
        "model3 = Sequential()\n",
        "model3.add(createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, False))\n",
        "model3.add(GlobalAveragePooling1DMasked())\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# model3 summary\n",
        "model3.summary()\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 50)          20000050  \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_mas (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 20,000,101\n",
            "Trainable params: 51\n",
            "Non-trainable params: 20,000,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWKAivATYT90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf681f31-29dc-461e-e01d-ffcc20a2b7ff"
      },
      "source": [
        "X_val = np.array(X_train_enc[:10000])\n",
        "partial_X_train = np.array(X_train_enc[10000:])\n",
        "\n",
        "y_val = np.array(y_train[:10000])\n",
        "partial_y_train = np.array(y_train[10000:])\n",
        "\n",
        "history = model3.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 86us/step - loss: 0.6969 - acc: 0.5049 - val_loss: 0.6946 - val_acc: 0.4996\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6938 - acc: 0.5003 - val_loss: 0.6935 - val_acc: 0.5047\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6930 - acc: 0.5130 - val_loss: 0.6928 - val_acc: 0.5144\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6922 - acc: 0.5223 - val_loss: 0.6921 - val_acc: 0.5241\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6914 - acc: 0.5336 - val_loss: 0.6913 - val_acc: 0.5358\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6906 - acc: 0.5427 - val_loss: 0.6906 - val_acc: 0.5428\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6898 - acc: 0.5533 - val_loss: 0.6901 - val_acc: 0.5446\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6892 - acc: 0.5563 - val_loss: 0.6895 - val_acc: 0.5467\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6885 - acc: 0.5609 - val_loss: 0.6889 - val_acc: 0.5508\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6879 - acc: 0.5630 - val_loss: 0.6883 - val_acc: 0.5565\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6872 - acc: 0.5697 - val_loss: 0.6877 - val_acc: 0.5611\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6866 - acc: 0.5736 - val_loss: 0.6872 - val_acc: 0.5631\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6860 - acc: 0.5728 - val_loss: 0.6869 - val_acc: 0.5603\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6855 - acc: 0.5749 - val_loss: 0.6863 - val_acc: 0.5646\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6851 - acc: 0.5719 - val_loss: 0.6859 - val_acc: 0.5656\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6845 - acc: 0.5754 - val_loss: 0.6854 - val_acc: 0.5685\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6840 - acc: 0.5771 - val_loss: 0.6851 - val_acc: 0.5678\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6836 - acc: 0.5751 - val_loss: 0.6846 - val_acc: 0.5715\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6831 - acc: 0.5777 - val_loss: 0.6842 - val_acc: 0.5727\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6827 - acc: 0.5793 - val_loss: 0.6840 - val_acc: 0.5707\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6823 - acc: 0.5777 - val_loss: 0.6836 - val_acc: 0.5712\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6819 - acc: 0.5783 - val_loss: 0.6832 - val_acc: 0.5737\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6815 - acc: 0.5781 - val_loss: 0.6830 - val_acc: 0.5721\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6811 - acc: 0.5793 - val_loss: 0.6826 - val_acc: 0.5741\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6808 - acc: 0.5801 - val_loss: 0.6823 - val_acc: 0.5735\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6804 - acc: 0.5803 - val_loss: 0.6820 - val_acc: 0.5746\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6801 - acc: 0.5811 - val_loss: 0.6817 - val_acc: 0.5755\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6797 - acc: 0.5809 - val_loss: 0.6814 - val_acc: 0.5764\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6794 - acc: 0.5827 - val_loss: 0.6811 - val_acc: 0.5769\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6792 - acc: 0.5814 - val_loss: 0.6808 - val_acc: 0.5787\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6788 - acc: 0.5841 - val_loss: 0.6806 - val_acc: 0.5780\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6784 - acc: 0.5835 - val_loss: 0.6804 - val_acc: 0.5777\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6783 - acc: 0.5840 - val_loss: 0.6800 - val_acc: 0.5804\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6778 - acc: 0.5835 - val_loss: 0.6799 - val_acc: 0.5769\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6775 - acc: 0.5854 - val_loss: 0.6796 - val_acc: 0.5802\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6773 - acc: 0.5857 - val_loss: 0.6793 - val_acc: 0.5804\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6770 - acc: 0.5862 - val_loss: 0.6791 - val_acc: 0.5817\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6767 - acc: 0.5874 - val_loss: 0.6788 - val_acc: 0.5817\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6764 - acc: 0.5880 - val_loss: 0.6786 - val_acc: 0.5823\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6762 - acc: 0.5879 - val_loss: 0.6784 - val_acc: 0.5832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQRPtY0AZ9Kl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ac45222f-b911-4dd6-bdbc-b433337006f4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hU5bb48e8ighQRELBcSoIVEwgI\nEQsoXmxgwYIFxYLKj4Me7A3FcxAVvfZy9arg0YMSRdQDIhYUbGAlSJGigDRBkEhRIIiErN8f755k\nCDOTSabsyWR9nmeezG4za/bAXvOW/b6iqhhjjDHl1fI7AGOMManJEoQxxpiQLEEYY4wJyRKEMcaY\nkCxBGGOMCckShDHGmJAsQZioiUiGiGwRkdbx3NdPInKwiMS9r7eInCQiy4OWfxSR46LZtwrv9YKI\n3FnV440JZw+/AzCJIyJbghbrA9uBnd7y31Q1vzKvp6o7gb3ivW9NoKqHxeN1RGQAcImqnhD02gPi\n8drGlGcJIo2paukF2vuFOkBVp4TbX0T2UNXiZMRmTEXs36P/rIqpBhOR+0TkdRF5TUQ2A5eIyDEi\n8rWIbBKRNSLylIjU9vbfQ0RURLK85THe9vdFZLOIfCUibSq7r7e9l4gsEpHfReR/ReQLEekfJu5o\nYvybiCwRkY0i8lTQsRki8riIrBeRpUDPCOdnqIiMLbfuGRF5zHs+QEQWep/nJ+/XfbjXWiUiJ3jP\n64vIK15s84HO5fa9S0SWeq87X0R6e+vbA08Dx3nVd78Fndu7g44f5H329SIyQUQOiObcVOY8B+IR\nkSkiskFE1orIbUHv8w/vnPwhIgUi8l+hqvNEZHrge/bO5+fe+2wA7hKRQ0TkE+89fvPOW6Og4zO9\nz1jobX9SROp6MR8etN8BIlIkIk3DfV4TgqraowY8gOXASeXW3Qf8BZyJ+7FQDzgSOApXujwQWAQM\n9vbfA1Agy1seA/wG5AG1gdeBMVXYd19gM3CWt+0mYAfQP8xniSbGt4FGQBawIfDZgcHAfKAl0BT4\n3P03CPk+BwJbgAZBr70OyPOWz/T2EaAHsA3I9badBCwPeq1VwAne80eAT4EmQCawoNy+FwAHeN/J\nxV4M+3nbBgCflotzDHC39/wUL8aOQF3g/4CPozk3lTzPjYBfgeuBPYG9gS7etjuAOcAh3mfoCOwD\nHFz+XAPTA9+z99mKgauBDNy/x0OBE4E63r+TL4BHgj7PPO98NvD27+ptGwmMCHqfm4Hxfv8/rG4P\n3wOwR5K+6PAJ4uMKjrsFeMN7Huqi/1zQvr2BeVXY90pgWtA2AdYQJkFEGePRQdv/A9ziPf8cV9UW\n2HZa+YtWudf+GrjYe94L+DHCvpOAv3vPIyWIlcHfBXBN8L4hXncecLr3vKIEMRq4P2jb3rh2p5YV\nnZtKnudLgRlh9vspEG+59dEkiKUVxHBe4H2B44C1QEaI/boCywDxlmcD58b7/1W6P6yKyfwcvCAi\nbUXkXa/K4A/gHqBZhOPXBj0vInLDdLh9/ys4DnX/o1eFe5EoY4zqvYAVEeIFeBW4yHt+sbcciOMM\nEfnGq/7YhPv1HulcBRwQKQYR6S8ic7xqkk1A2yhfF9znK309Vf0D2Ai0CNonqu+sgvPcCpcIQom0\nrSLl/z3uLyLjRGS1F8O/y8WwXF2HiF2o6he40kg3EWkHtAberWJMNZYlCFO+i+fzuF+sB6vq3sA/\ncb/oE2kN7hcuACIi7HpBKy+WGNfgLiwBFXXDHQecJCItcFVgr3ox1gPeBB7AVf80Bj6MMo614WIQ\nkQOBZ3HVLE291/0h6HUr6pL7C67aKvB6DXFVWaujiKu8SOf5Z+CgMMeF27bVi6l+0Lr9y+1T/vM9\niOt9196LoX+5GDJFJCNMHC8Dl+BKO+NUdXuY/UwYliBMeQ2B34GtXiPf35LwnpOATiJypojsgavX\nbp6gGMcBN4hIC6/B8vZIO6vqWlw1yL9x1UuLvU174urFC4GdInIGrq482hjuFJHG4u4TGRy0bS/c\nRbIQlyv/H64EEfAr0DK4sbic14CrRCRXRPbEJbBpqhq2RBZBpPM8EWgtIoNFZE8R2VtEunjbXgDu\nE5GDxOkoIvvgEuNaXGeIDBEZSFAyixDDVuB3EWmFq+YK+ApYD9wvruG/noh0Ddr+Cq5K6mJcsjCV\nZAnClHczcDmu0fh5XGNyQqnqr8CFwGO4//AHAbNwvxzjHeOzwFTge2AGrhRQkVdxbQql1Uuqugm4\nERiPa+g9D5foojEMV5JZDrxP0MVLVecC/wt86+1zGPBN0LEfAYuBX0UkuKoocPwHuKqg8d7xrYF+\nUcZVXtjzrKq/AycDfXBJaxHQ3dv8MDABd57/wDUY1/WqDv8fcCeuw8LB5T5bKMOALrhENRF4KyiG\nYuAM4HBcaWIl7nsIbF+O+563q+qXlfzshrIGHGNShldl8AtwnqpO8zseU32JyMu4hu+7/Y6lOrIb\n5UxKEJGeuB5D23DdJHfgfkUbUyVee85ZQHu/Y6murIrJpIpuwFJc3fupwDnWqGiqSkQewN2Lcb+q\nrvQ7nurKqpiMMcaEZCUIY4wxIaVNG0SzZs00KyvL7zCMMaZamTlz5m+qGrJbedokiKysLAoKCvwO\nwxhjqhURCTuagFUxGWOMCckShDHGmJAsQRhjjAkpbdogQtmxYwerVq3izz//9DsUE0HdunVp2bIl\ntWuHG17IGOOHtE4Qq1atomHDhmRlZeEGCDWpRlVZv349q1atok2bNhUfYIxJmrSuYvrzzz9p2rSp\nJYcUJiI0bdrUSnnGhJCfD1lZUKuW+5ufX7ntsUrrEgRgyaEasO/ImN3l58PAgVBU5JZXrHDLAP36\nVbw9HtK6BGGMMaksUglg6NCyi39AUZFbH832eLAEkUDr16+nY8eOdOzYkf33358WLVqULv/1119R\nvcYVV1zBjz/+GHGfZ555hvx4ly2NMQkVKAGsWAGqZSWAwH/llWGGGAysr2h7XPg9KXa8Hp07d9by\nFixYsNu6SMaMUc3MVBVxf8eMqdThEQ0bNkwffvjh3daXlJTozp074/dG1VRlvytjqotw15XMTFWX\nGnZ9ZGbGZ3u0gAINc121EoSnomweT0uWLCE7O5t+/fqRk5PDmjVrGDhwIHl5eeTk5HDPPfeU7tut\nWzdmz55NcXExjRs3ZsiQIXTo0IFjjjmGdevWAXDXXXfxxBNPlO4/ZMgQunTpwmGHHcaXX7qJtLZu\n3UqfPn3Izs7mvPPOIy8vj9mzZ+8W27BhwzjyyCNp164dgwYNQr3RfhctWkSPHj3o0KEDnTp1Yvny\n5QDcf//9tG/fng4dOjA0nmVbY6qJSNVEka4rFZUARoyA+vV33Va/vlsfzfa4CJc5qtsj1hJEvLJx\nOMEliMWLF6uI6IwZM0q3r1+/XlVVd+zYod26ddP58+erqmrXrl111qxZumPHDgX0vffeU1XVG2+8\nUR944AFVVR06dKg+/vjjpfvfdtttqqr69ttv66mnnqqqqg888IBec801qqo6e/ZsrVWrls6aNWu3\nOANxlJSUaN++fUvfr1OnTjpx4kRVVd22bZtu3bpVJ06cqN26ddOioqJdjq0KK0GYVBWpZmHMGNX6\n9Xe9ZtSvH10pIZprTkW1GvGo9cBKEBVLSn1ekIMOOoi8vLzS5ddee41OnTrRqVMnFi5cyIIFC3Y7\npl69evTq1QuAzp07l/6KL+/cc8/dbZ/p06fTt29fADp06EBOTk7IY6dOnUqXLl3o0KEDn332GfPn\nz2fjxo389ttvnHnmmYC7sa1+/fpMmTKFK6+8knr16gGwzz77VP5EGJPCKqpZqKihONJ1JZoSQL9+\nsHw5lJS4v+V7J1W0PVaWIDytW1dufawaNGhQ+nzx4sU8+eSTfPzxx8ydO5eePXuGvC+gTp06pc8z\nMjIoLi4O+dp77rlnhfuEUlRUxODBgxk/fjxz587lyiuvtPsTTI0WSwKAyNeVfv1g5EjIzAQR93fk\nyPhf5GNhCcKTlPq8MP744w8aNmzI3nvvzZo1a5g8eXLc36Nr166MGzcOgO+//z5kCWXbtm3UqlWL\nZs2asXnzZt566y0AmjRpQvPmzXnnnXcAdwNiUVERJ598Mi+++CLbtm0DYMOGDXGP2xiI7YawWI6N\nJQFAxdeVRJcAYmUJwuNnNu/UqRPZ2dm0bduWyy67jK5du8b9Pa699lpWr15NdnY2w4cPJzs7m0aN\nGu2yT9OmTbn88svJzs6mV69eHHXUUaXb8vPzefTRR8nNzaVbt24UFhZyxhln0LNnT/Ly8ujYsSOP\nP/543OM2JpoOJOGSQCzHQnwSQKqXEiIK1zhR3R7x6Oaaznbs2KHbtm1TVdVFixZpVlaW7tixw+eo\nyth3ZcKpqDE3UkNxLMdGsz2wT6K6xycDERqpfb+wx+thCSKyjRs3aqdOnTQ3N1fbt2+vkydP9juk\nXdh3ld5iuYiKhL7Ii7jtkZJALMfGI/bqIFKCSPuxmIzTuHFjZs6c6XcYpgaKdcyg1q3dMaHWQ+R2\ngliODejXL/WqhFRh8WL4+GP3aNQIRo2K//tYG4QxJqFiHTOoonr+SO0EsRybalauhH//Gy67DFq1\ngsMOg6uvhi+/BK+nedxZgjDGJFQ0v9IjNRRX1NAbKQnEcqxfSkpg6VKYOBHuvx8uvhgOPtjFfsUV\n8P770LUrPPccLFoEP/8MTz2VmFisiskYE5X8fPerP1B1E7gAV7StomqeaKqgIlXzBNaHe/9Yjo2H\n336DSZNg69bw+xQVwcKFMG8ezJ+/a4krMxM6doRrr4UePSAnxyXSpAjXOFHdHtZIXb3Zd+W/qg4p\nEWtPoEQPc+OH7dtVJ0xQPfts1dq1Q3++8o/99lM98UTV669XHTVK9auvVH//PfGx4lcvJqAn8COw\nBBgSYnt/oBCY7T0GBG17CJgPLASeAiTSe6VigjjhhBP0gw8+2GXd448/roMGDYp4XIMGDVRVdfXq\n1dqnT5+Q+3Tv3n2XsZxCefzxx3Xr1q2ly7169dKNGzdGE3rS+f1d1QSpOqZQRT2NqouSEtXvvlO9\n7jrVZs3KLvo336w6a5bqunXhH37+t/QlQQAZwE/AgUAdYA6QXW6f/sDTIY49FvjCe40M4CvghEjv\nl4oJ4vnnn9f+/fvvsu6oo47Szz77LOJxgQQRSTQJIjMzUwsLCysONAX4/V2lu1h/xUe6iMd6gU9G\nCWLVKtVnnlH988+qHb9zp+ovv6j+8IPqN9+ofvih6ptvqv7rX6qPPaY6dKhq+/Yu7jp1VM8/X3XS\nJNUUutUoLL8SxDHA5KDlO4A7yu0TLkEcA8wE6gH1gQLg8Ejvl4oJYv369dq8eXPdvn27qqouW7ZM\nW7VqpSUlJbp582bt0aOHHnHEEdquXTudMGFC6XGBBLFs2TLNyclRVdWioiK98MILtW3btnr22Wdr\nly5dShPEoEGDtHPnzpqdna3//Oc/VVX1ySef1Nq1a2u7du30hBNOUNVdE8ajjz6qOTk5mpOTUzoS\n7LJly7Rt27Y6YMAAzc7O1pNPPrl0pNZgEydO1C5dumjHjh31xBNP1LVr16qq6ubNm7V///7arl07\nbd++vb755puqqvr+++/rEUccobm5udqjR4+Q58rv7ype/OwzH+m9Y0kAFR0f6wU+mpvRYjF1quq+\n+7rXPeOMyieJdetU8/JCf8bgR5cuqv/3f6oxDGrsC78SxHnAC0HLl5ZPBl6CWAPMBd4EWgVtewTY\nBPwOjAjzHgO95FHQunXr3T548EXn+utVu3eP7+P66ys++aeffnrpxf+BBx7Qm2++WVXdnc2/exWM\nhYWFetBBB2lJSYmqhk4Qjz76qF5xxRWqqjpnzhzNyMgoTRCBYbaLi4u1e/fuOmfOHFXdvQQRWC4o\nKNB27drpli1bdPPmzZqdna3fffedLlu2TDMyMkqHAT///PP1lVde2e0zbdiwoTTWUaNG6U033aSq\nqrfddpteH3RSNmzYoOvWrdOWLVvq0qVLd4m1vHRIEIm+0MXy3rHeMBZLG0S08cc7se7cqfrAA6q1\naqkefrjqsGEutjPPjD5J/Pyzatu2qvXqqT70kGp+visZTJumOmeO6vLlqhs2qBYXxx6vXyIlCL+7\nub4DZKlqLvARMBpARA4GDgdaAi2AHiJyXPmDVXWkquapal7z5s2TGHb0LrroIsaOHQvA2LFjueii\niwCXmO+8805yc3M56aSTWL16Nb/++mvY1/n888+55JJLAMjNzSU3N7d027hx4+jUqRNHHHEE8+fP\nDzkQX7Dp06dzzjnn0KBBA/baay/OPfdcpk2bBkCbNm3o2LEjEH5I8VWrVnHqqafSvn17Hn74YebP\nnw/AlClT+Pvf/166X5MmTfj66685/vjjadOmDZDeQ4LHY47giiafqer8xYkcUyge4w3Fe9C6TZvg\nnHPgjjvg/PPh22/h7rvh2WfhnXfcuu3bI7/G0qVw3HGwejVMngy33uq6nJ5+OnTrBrm57rM2aQIZ\nGbHFm6oS2c11NdAqaLmlt66Uqq4PWnwB1zANcA7wtapuARCR93HVTtOqGow34VrSnXXWWdx44418\n9913FBUV0blzZ8ANfldYWMjMmTOpXbs2WVlZVRpae9myZTzyyCPMmDGDJk2a0L9//5iG6A4MFQ5u\nuPDASK3Brr32Wm666SZ69+7Np59+yt13313l96tuInXnjLa/f6SuouG6e0LkrqDRzE4WfDzsngAg\ncnfPirqLxnJR//VXeOwxWLcOOnWCzp1d187ySSsas2fDeee5c/TUUzB4sEtcAIMGuTLONde4JPHm\nmxA0in6pBQvgpJPgr7/cncpBU7fULOGKFrE+cMlnKdCGskbqnHL7HBD0PJAUAC4EpnivURuYCpwZ\n6f1SsQ0i4IILLtAOHTqUtg+oqj7xxBM6ePBgVVX9+OOPFdBly5apavgqpquuukpVVb///vvSKqbZ\ns2drbm6u7ty5U9euXav77ruvvvTSS6qq2q5du9KqHdWyKqaZM2dq+/btdevWrbplyxbNyckprWIK\nvJ+q6sMPP6zDhg3b7fN07NhRCwoKVFW1f//+2r17d1VVvf3229O6iinWht5E9hSqrmMKrV+vOmSI\nOw+1aqk2b14We61aqu3aqV5+uepTT6l+8YXq2rWRG35fekm1bl3VFi3c/uE884x7j969XZfUYAUF\nqk2bqu6/v+q8efH4lKkNH7u5ngYswvVmGuqtuwfo7T1/ANeVdQ7wCdDWW58BPI/r4roAeKyi90rl\nBDF+/HgFdOHChaXrCgsL9eijj9Z27dpp//79tW3bthETRHAj9TnnnLNLI/Xll1+uhxxyiPbo0UPP\nOeec0gTx1FNP6aGHHlqpRupoEsSECRO0TZs22qlTJ73llltKE8TmzZv1sssu05ycHM3NzdW33npL\nVVXfe+897dixo+bm5upJJ50U8hwl87uq6oUykQlANbaeQn62f1TF77+rDh+uuvfeLta+fV0PoZIS\nV+8/YYLqP/6h2qtXWQNz8Gdu1kw1O1v1hBNUL7hAdfBg9xdUe/RQ/fXXimN4+mm3/1lnlSWJzz93\nMWVmqi5enNBTkDJ8SxDJfKRygjAVS9Z3FcuFNJrunLH090/0/MWpYMsW1QcfVN1nHxf/2We7xt5I\nAknj7bfdL/9//lN10CDVc89V7dZN9dBDVRs3djek3XFH5RqMA0ni7LNd43O9eqqHHeber6awBGFS\nXrK+q1i6ZMbandPvnkLJtm2bq6IZP971ABo40N04Bq5kUMFtPJW2c2fVjgskCVDt2DG60kc6sQRh\nUl48v6tE3bUb60U61slnUrmE8PPPqqNHu1/2PXqotmq1+7lu2lS1Z0/XRTTVjBzpqqhSdKCBhKrR\nCSLQX9+krpKSkrgliHg0JEe6CMd6kU7li3xl/Pqr6uuvq/7tb6qHHFJ2Hhs3Vj36aNVLLnFtDPn5\nqt9+6+4VMKkpUoIQt736y8vL04KCgl3WLVu2jIYNG9K0aVMk0M/NpBRVZf369WzevLn0XolIXUEr\nkpUVeuTQzEzXv758V1JwXSlHjnTPw21LtQljkm3TJvj887IJar7/3q1v2BC6d4cTT3QjjbZrl8SR\nRk1ciMhMVQ3ZkTetE8SOHTtYtWpVTPcFmMSrW7cuLVu2pHbt2hEv4NFcpGvVcr9lyxNxN2FB+ARU\nUXKpSbZuhS++KEsIM2e681e3rrtJrEcP9+jcGfawSQOqtRqbIIx/qloKiPUiHcvx0SSXdKUKc+fC\n22/DlCnw9dewY4e7+B99dFlCOPpoCLqX0qSBSAnCcr+Ju1jmII7mbuRIKrpjOJKKJrapDhYsgIIC\nOPxwyM6GBg3C77tzp5uucsIEGD8eli1zybBzZ7jxRpcQunaFvfZKXvwmxYRrnKhuj1CN1MYfsTQE\nx2Po56o2BKdCV9ING1y3y7lzK3fcunWqV1/t7j4Ojv/AA93dwnfeqfrqq+6eg3ffVR0woOwGtDp1\nXLfTkSPdncqmZqGm9mIy/ojUlTTW2ccSzc9eRp995rqHBj53z56qH3/sbhQLZ/t2Nx9Bo0aqGRmq\n117rksD48ar33qt64YWqOTmqe+yx6zlt2NBtGzs2ObOWmdRlCcIkVaLvCPa7q+jy5ao//hi/1/vr\nL/cLX8R1GZ0yRXXEiLKbyjp3dhfy4DGISkrcnb+HHlqWTCL1FN6+XfX771Vfe031vfeqPnGOST+W\nIExSRSoFxDr7mF8ljNWrVZ94wvXxD7zvpZe6mcpisWSJm2gGVK+8UnXz5rJt27a5ap9AEmjTxg1a\nN2OG6imnuHWHHeaqjIypKksQJunC/cpP9HAV8VRYqPrcc25AuEBi69DBTUJz++2u7r5+fdV77lEN\nMfFeRCUlqv/+t+pee7mby8aNC7/vzp2uyuiYY8o+b+PGLmH99Vdsn9EYSxAmZcRaAkjGBPcLFrhG\n20C9/aGHutnIylfh/PSTap8+bp/WrV01UDQ37m/c6EYvBdXjj1ddsSL62KZPd20O1WSqcVMNREoQ\ndh+ESbpE3ikdq59+cjeCFRfDVVdB377QoUPZhDOhfPop3HADzJnjuoU+8YSbYOaPP2DxYvdYsqTs\n7/z5sGULDB8OQ4ak72xkpnqIdB+E77/84/WwEkRy+dVQnMg2iJ9/Vs3KcoPKVXaimOJi1VGjyrqO\nNmu2eymnRQs3l/mAAarffBN7vMbEAxFKEHajnKm0WG6Ei1U0U2NWRWEhnHwyrF8Pn3wCOTmVOz4j\nAwYMgAsugEcfdfMYH3KIexx8MBx0UOSb1oxJRVbFZCot3cYs2rTJ3TX8ww9ucvrjjvM7ImOSx4ba\nMHEV63AYqWTrVjj9dJg3DyZOtORgTDAbmNdUWrixiarTmEUA27fDOee4gelefRV69vQ7ImNSiyUI\nU2kjRrgB8IJFOyBeMsyfD8ce63oj3XADvPKKG8Ru586yfYqL4aKL4KOP4IUX4Lzz/IvXmFRlVUym\n0hLVUBwP777rLvz167vG4VGj4Mkn3bYGDeCII9xopStXuhFMn3wSrrjC35iNSVXWSG3Sgio89hjc\neit07OjaE1q2dKWGH35wE94UFLi/s2bBtm1w771w111+R26Mv6yR2qS17dvh6qvhpZegTx8YPbqs\nS2lGhuuympMDl13m1hUXu55LzZr5F7Mx1YG1QZhqrbAQTjrJJYd//APGjav4foM99rDkYEw0rARh\nqq158+DMM2HtWhg7Fi680O+IjEkvVoIw1c7vv7sSwzHHuOqlzz+35GBMIlgJwqQ8VZg7F95/3z2+\n+MI1PuflufmUW7TwO0Jj0pMlCJOStm2D995zCeGDD9zYRuB6KN12G5x2Ghx9tGtPMMYkhv33Miln\n+3Y3cN4XX0CjRu55r17uTuf/+i+/ozOm5rA2CBNSfr4blK9WLfc3Pz8576sKgwe75PDCC66X0htv\nwJVXWnIwJtmsBGF24+dw3s8+6xLDnXe6CXuMMf6xEoTZzdChZckhoKjIrY9GSYkb/+iEE2Dq1Ojf\n97PP4Prr4Ywz3F3Oxhh/WYIwu4llOO+vvnLdTy+7DGbMgFNOcUNgVDSiy4oVbsC8gw6CMWNc1ZYx\nxl/239DspirDef/8s6t+OvZY93z0aFizBs4+G26+GS69dPdSScDWrW6/HTvg7bddw7Qxxn+WIGqo\nSI3QlRnOu6gIhg+Hww6Dt95y1VCLFrkSxN57w5tvwn33ufkWunbdfSY6VdfWMGcOvPaaex1jTIoI\nN1l1dXt07tw5PjN41wBjxqjWr6/qLs/uUb++Wx+8T2amqoj7G7wtYNw41ZYt3fEXXKC6fHn495w0\nSbVRI9VmzVQ//rhs/QMPuOMffDBen84YUxlAgYa5rib0og30BH4ElgBDQmzvDxQCs73HgKBtrYEP\ngYXAAiAr0ntZgoheZuauySHwyMyM/jX+8x93TKdOqtOmRXfMjz+qHn64akaG6uOPu6QhonrRRaol\nJVX5JMaYWEVKEAmbD0JEMoBFwMnAKmAGcJGqLgjapz+Qp6qDQxz/KTBCVT8Skb2AElUNU4tt80FU\nRq1aoRuNRVwPpIr89JObdOeww2DaNKhTJ/r3/uMPuPxyN0RGRgbk5sL06btXaRljkiPSfBCJbIPo\nAixR1aWq+hcwFjgrmgNFJBvYQ1U/AlDVLZGSg6mcWOaU/vNPOP98l2Ref71yyQFcu8Rbb8E990D7\n9i5RWHIwJjUlMkG0AH4OWl7lrSuvj4jMFZE3RaSVt+5QYJOI/EdEZonIw16JZBciMlBECkSkoLCw\nMP6fIE3FMqf0jTe6Gdleftk1bldFrVpu7oZZs6JLSsYYf/jdi+kdXNtCLvARMNpbvwdwHHALcCRw\nIK69YheqOlJV81Q1r3nz5smJOA306wcjR0JmpqtWysx0yxXdJf3qq/Dcc26wvDPOSE6sxhj/JDJB\nrAZaBS239NaVUtX1qrrdW3wB6Ow9XwXM9qqnioEJQKcExlrj9OsHy5e7NoflyytODj/84Ibb6NbN\ndVs1xqS/RCaIGcAhItJGROoAfYGJwTuIyAFBi71xPZYCxzYWkUCxoAeuJ5Pxwdat7i7nevXczG21\na/sdkTEmGRI2WJ+qFovIYDmb6HYAABdVSURBVGAykAG8qKrzReQeXLeqicB1ItIbKAY24FUjqepO\nEbkFmCoiAswERiUqVhOeKlxzDSxYAJMn2+Q8xtQkCevmmmzWzXVX+fnuruaVK11D8IgRVRuJ9cUX\n3Z3Ow4bB3XfHPUxjjM8idXO14b7TULyG6547F/7+dzjxRNfryBhTs/jdi8kkQKzDdYOb1a1vX2jS\nxCWcjN06GRtj0p2VINJQLMN1BzzyCCxcCO++C/vtF5+4jDHVi5Ug0lAsd0oDLFvmurL26QOnnRa/\nuIwx1YsliDQUy53SqnDtta5K6fHHExOfMaZ6sASRhqp6pzS4sZHefdfN8dCqVcX7G2PSlyWIairS\nhD9Q+TulAbZsgeuuc4PoXXdd/GM2xlQv1khdDcWrG2t599wDq1bZ3dLGGMdKENVQPLqxljdvnmtz\nuPJKNzWoMcZYgqiG4tGNNVhJCVx9tZur4cEHqx6XMSa9VJggRORaEWmSjGBMdGLtxlre6NFuVreH\nHoJmzaoelzEmvURTgtgPmCEi40Skpzd4nvFRLN1Yy1u/Hm69FY49Fq64Ij7xGWPSQ4UJQlXvAg4B\n/oUbbXWxiNwvIgclODYTRizdWMu74w7YtAmefdb1iDLGmICoejGpqorIWmAtbmjuJsCbIvKRqt6W\nyABNaP36xdZjCeCrr2DUKLjpJsjNjU9cxpj0UWGCEJHrgcuA33Czvt2qqjtEpBawGLAEUQ2tW+cS\nTMuWNoy3MSa0aEoQ+wDnquqK4JWqWiIiNjNxNfTnn3D22bBmDXz2GTRs6HdExphUFE2t8/u42d4A\nEJG9ReQoAFVdGPYok5JUXWP0V1/BK69Aly5+R2SMSVXRJIhngS1By1u8daYauvtud6f0Aw+4eaaN\nMSacaBKEaNC8pKpagg3RUS2NGeOG07jiCrj9dr+jMcakumgSxFIRuU5EanuP64GliQ7MxNf06W5u\n6RNOgOeec91jjTEmkmgSxCDgWGA1sAo4ChiYyKBMfP30k2uUzsqCt96COnX8jsgYUx1UWFWkquuA\nvkmIxSTAxo1w+umucfrdd2GfffyOyBhTXURzH0Rd4CogB6gbWK+qVyYwLhMHf/3lpg1duhSmToWD\nD/Y7ImNMdRJNFdMrwP7AqcBnQEtgcyKDMrH79ls3vtInn8C//gXHHed3RMaY6iaaBHGwqv4D2Kqq\no4HTce0QJgWtX+8mDzr6aPjlF3j9dbj0Ur+jMsZUR9EkiB3e300i0g5oBOybuJBMVZSUuAH7Dj0U\nXnwRbrwRfvgBLrjA78iMMdVVNPczjPTmg7gLmAjsBfwjoVGZSikogGuugRkzoHt3ePppaNfO76iM\nMdVdxAThDcj3h6puBD4HDkxKVCYqv/7q7ox+/nnYbz93I9zFF9s9DsaY+IhYxeTdNW2jtaaYDRvc\nPA4HHuiG677+eled1K+fJQdjTPxEU8U0RURuAV4HtgZWquqG8IeYRPj9d3jiCXjsMdi8GS66CIYN\nc+0OxhgTb9EkiAu9v38PWqdYdVPC5efD0KGwYgU0bgzFxbBlC5x7Lgwfbu0MxpjEiuZO6jbJCMTs\nKj/fdVctKnLLmza5KUHvvRfuusvf2IwxNYMEDdQaegeRy0KtV9WXExJRFeXl5WlBQYHfYcRNVpYr\nOZSXmQnLlyc7GmNMuhKRmaqaF2pbNFVMRwY9rwucCHwHpFSCSDcrV1ZuvTHGxFs0VUzXBi+LSGNg\nbMIiMgDsu6/rxlpe69bJj8UYUzNFcyd1eVuBqNolRKSniPwoIktEZEiI7f1FpFBEZnuPAeW27y0i\nq0Tk6SrEWa01bbr7uvr1YcSI5MdijKmZohnN9R1cryVwCSUbGBfFcRnAM8DJuHkkZojIRFVdUG7X\n11V1cJiXuRd3g16NMm0aLFjg7muYPt1VK7Vu7ZJDv35+R2eMqSmiaYN4JOh5MbBCVVdFcVwXYImq\nLgUQkbHAWUD5BBGSiHQG9gM+AEI2oKSr4cPdndEjR7pSgzHG+CGaKqaVwDeq+pmqfgGsF5GsKI5r\nAfwctLzKW1deHxGZKyJvikgrKB3i41HglijeJ61Mm+bmbrj9dksOxhh/RZMg3gBKgpZ3euvi4R0g\nS1VzgY+A0d76a4D3KiqpiMhAESkQkYLCwsI4heSvQOnhb3/zOxJjTE0XTRXTHqr6V2BBVf8SkWhm\nNV4NtApabumtK6Wq64MWXwAe8p4fAxwnItfgRo+tIyJbVHVIueNHAiPB3QcRRUwpbfp0V3p49FEr\nPRhj/BdNCaJQRHoHFkTkLOC3KI6bARwiIm28hNIXN1x4KRE5IGixN7AQQFX7qWprVc3CVTO9XD45\npKPhw1331kGD/I7EGGOiK0EMAvKDupquAkLeXR1MVYtFZDAwGcgAXlTV+SJyD1CgqhOB67zkUwxs\nAPpX4TOkhS++gClT4JFHrPRgjEkNFQ61UbqjyF4AqroloRFVUXUfauOUU2DOHFi6FBo08DsaY0xN\nEWmojQqrmETkfhFprKpbVHWLiDQRkfviH2bN9eWX8NFHcOutlhyMMakjmjaIXqq6KbDgzS53WuJC\nqnmGD4fmzeHqq/2OxBhjykSTIDJEZM/AgojUA/aMsL+phC+/hA8/tNKDMSb1RNNInQ9MFZGXAME1\nJI+OeISJ2n33QbNmcM01fkdijDG7imY01wdFZA5wEm5MpslAZqIDqwnWr4fJk9380lZ6MMakmmhH\nc/0VlxzOB3rg3a9gYvPBB1BSAr17V7yvMcYkW9gEISKHisgwEfkB+F/cmEyiqv+tqjVu+O1EePpp\nN43oUUe5GeTy8/2OyBhjykSqYvoBmAacoapLAETkxqREVQOMHg1ff122vGKFm4MabEhvY0xqiFTF\ndC6wBvhEREaJyIm4RmoTB7ffvvu6oiIYOjT5sRhjTChhE4SqTlDVvkBb4BPgBmBfEXlWRE5JVoDp\nKtR0omBzThtjUkeFjdSqulVVX1XVM3Ejss4CQvz+NZWxR5jKPZtz2hiTKio1J7WqblTVkap6YqIC\nqgkWLYLiYqhde9f1Nue0MSaVVCpBmPiYNMn9feghyMwEEfd35EhroDbGpI5o7qQ2cTZpErRrBzfc\n4B7GGJOKrASRZJs2uXmnzzjD70iMMSYySxBJNnmya38480y/IzHGmMgsQSTZpElucL6jjvI7EmOM\nicwSRBIVF8N778Fpp0FGht/RGGNMZJYgkujrr2HDBmt/MMZUD5YgkmjSJHeD3Cl2H7oxphqwBJFE\n77wD3btDo0Z+R2KMMRWzBJEkS5fCggVWvWSMqT4sQSRJ4O5pSxDGmOrCEkSSTJoEbdvCwQf7HYkx\nxkTHEkQSbN4Mn35qpQdjTPViCSIJPvwQduywu6eNMdWLJYgkmDQJGjeGY4/1OxJjjImeJYgEKymB\nd9+FXr3CTxJkjDGpyBJEgn37LRQWWvWSMab6sQSRYJMmuXGXTj3V70iMMaZyLEEkkCqMGwfHHw/7\n7ON3NMYYUzmWIBLo3nth8WL45BPIyoL8fL8jMsaY6FmCSJD8fJcgAlasgIEDLUkYY6oPSxAJcued\nbv6HYEVFMHSoP/EYY0xlWYJIkJUrK7feGGNSjSWIBKlfP/T61q2TG4cxxlRVQhOEiPQUkR9FZImI\nDAmxvb+IFIrIbO8xwFvfUUS+EpH5IjJXRC5MZJzx9scfbmiN8jfG1a8PI0b4E5MxxlRWwhKEiGQA\nzwC9gGzgIhHJDrHr66ra0Xu84K0rAi5T1RygJ/CEiDROVKzxNn68SxBDh0JmJoi4vyNHQr9+fkdn\njDHRSeTgD12AJaq6FEBExgJnAQsqOlBVFwU9/0VE1gHNgU0JijWuxoyBAw+EYcPg7rv9jsYYY6om\nkVVMLYCfg5ZXeevK6+NVI70pIq3KbxSRLkAd4KcQ2waKSIGIFBQWFsYr7pj88gtMnQqXXOJKDsYY\nU1353Uj9DpClqrnAR8Do4I0icgDwCnCFqpaUP1hVR6pqnqrmNW/ePCkBV+S119wd1FaVZIyp7hKZ\nIFYDwSWClt66Uqq6XlW3e4svAJ0D20Rkb+BdYKiqfp3AOONqzBjo0gUOPdTvSIwxJjaJTBAzgENE\npI2I1AH6AhODd/BKCAG9gYXe+jrAeOBlVX0zgTHG1bx5MHu2q14yxpjqLmGN1KpaLCKDgclABvCi\nqs4XkXuAAlWdCFwnIr2BYmAD0N87/ALgeKCpiATW9VfV2YmKNx7GjHEjt15YrTrlGmNMaKKqfscQ\nF3l5eVpQUODb+5eUuK6sHTq4Ib6NMaY6EJGZqpoXapvfjdRp4/PPYdUqq14yxqQPSxBxMmYM7LUX\n9O7tdyTGGBMfliDi4M8/4Y03oE+f8GMwGWNMdWMJIg4mTXLjL1n1kjEmnViCiIMxY+CAA+C//9vv\nSIwxJn4sQcRo/Xp47z24+GLXxdUYY9KFJYgYvfGGG7n10kv9jsQYY+LLEkQM8vPhhhvc8969bb5p\nY0x6sQRRRfn5MGAAbPdGklq5EgYOtCRhjEkfliCqaOhQ1701WFGRW2+MMenAEkQVrVgRev3KlcmN\nwxhjEsUSRBXtv3/o9a1bJzcOY4xJFEsQVZSbu/u6+vVhxIjkx2KMMYlgCaIKduyAWbPcxECZmW5q\n0cxMGDnSZpIzxqSPhM0Hkc6mTIHCQhg1Cs46y+9ojDEmMawEUQVjxsA++0CvXn5HYowxiWMJopI2\nb4bx4+GCC6BOHb+jMcaYxLEEUUkTJsC2bTZyqzEm/VmCqKQxYyArC4491u9IjDEmsSxBVMKaNa6B\n+pJLXM8lY4xJZ5YgKmHsWCgpseolY0zNYAmiEl55BY48Eg47zO9IjDEm8SxBRGn+fHdznJUejDE1\nhSWIKOXnuxnjLrzQ70iMMSY5LEFEoaTEJYhTToH99vM7GmOMSY4anyDy81231Vq13N9QE/5Mn+6G\n8bbqJWNMTVKjx2LKz3ezwBUVueUVK9wy7Dro3pgx0KCBjbtkjKlZanQJYujQsuQQUH5WuD//hHHj\n4NxzXZIwxpiaokYniHCzvwWvf/55+P13q14yxtQ8NTpBhJv9LbD+xx9hyBA4/XQ4+eTkxWWMMamg\nRieIESPcLHDBArPCFRfDZZe55VGjbGgNY0zNU6MTRL9+bha4ULPC/c//wLffwrPPwgEH+B2pMcYk\nn6iq3zHERV5enhYUFMTltQLTiZ53Hrz2Wlxe0hhjUpKIzFTVvFDbanQJIpTt213VUvPm8Mwzfkdj\njDH+qdH3QYTyz3/CvHnw3ntuWlFjjKmprAQRZPp0ePhhd7Ncr17R3WVtjDHpKqEJQkR6isiPIrJE\nRIaE2N5fRApFZLb3GBC07XIRWew9Lk9knABbtsDll7tE8MgjZXdZr1gBqmV3WVuSMMbUFAlLECKS\nATwD9AKygYtEJDvErq+rakfv8YJ37D7AMOAooAswTESaJCpWgFtvhWXLYPRoaNgwurusjTEmnSWy\nBNEFWKKqS1X1L2AsEO1oRqcCH6nqBlXdCHwE9ExQnEyeDM89BzffDMcd59ZFc5e1Mcaks0QmiBbA\nz0HLq7x15fURkbki8qaItKrMsSIyUEQKRKSgsLCwSkFu3AhXXgk5OXDvvWXrK7rL2hhj0p3fjdTv\nAFmqmosrJYyuzMGqOlJV81Q1r3nz5lUKYMcOyMuDl1+GunXL1ke6y9oYY2qCRCaI1UCroOWW3rpS\nqrpeVbd7iy8AnaM9Nl723Rfefhs6ddp1faS7rI0xpiZIZIKYARwiIm1EpA7QF5gYvIOIBA9i0RtY\n6D2fDJwiIk28xulTvHVJ1a8fLF/uZpRbvtySgzGmZknYjXKqWiwig3EX9gzgRVWdLyL3AAWqOhG4\nTkR6A8XABqC/d+wGEbkXl2QA7lHVDYmK1RhjzO5sLCZjjKnBbCwmY4wxlWYJwhhjTEiWIIwxxoRk\nCcIYY0xIliCMMcaElDa9mESkEFgRYZdmwG9JCqeyLLaqsdiqxmKrmnSNLVNVQw5FkTYJoiIiUhCu\nK5ffLLaqsdiqxmKrmpoYm1UxGWOMCckShDHGmJBqUoIY6XcAEVhsVWOxVY3FVjU1LrYa0wZhjDGm\ncmpSCcIYY0wlWIIwxhgTUtonCBHpKSI/isgSERnidzzlichyEfleRGaLiK/D0YrIiyKyTkTmBa3b\nR0Q+EpHF3t8mKRTb3SKy2jt3s0XkNB/iaiUin4jIAhGZLyLXe+t9P28RYkuF81ZXRL4VkTlebMO9\n9W1E5Bvv/+vr3lwyqRLbv0VkWdB565js2IJizBCRWSIyyVtOzHlT1bR94Oah+Ak4EKgDzAGy/Y6r\nXIzLgWZ+x+HFcjzQCZgXtO4hYIj3fAjwYArFdjdwi8/n7ACgk/e8IbAIyE6F8xYhtlQ4bwLs5T2v\nDXwDHA2MA/p6658Drk6h2P4NnOfneQuK8SbgVWCSt5yQ85buJYguwBJVXaqqfwFjgbN8jillqern\nuImbgp1F2Vzho4GzkxqUJ0xsvlPVNar6nfd8M25WxBakwHmLEJvv1NniLdb2Hgr0AN701vt13sLF\nlhJEpCVwOm6aZkRESNB5S/cE0QL4OWh5FSnyHySIAh+KyEwRGeh3MCHsp6prvOdrgf38DCaEwSIy\n16uC8qX6K0BEsoAjcL84U+q8lYsNUuC8edUks4F1wEe40v4mVS32dvHt/2v52FQ1cN5GeOftcRHZ\n04/YgCeA24ASb7kpCTpv6Z4gqoNuqtoJ6AX8XUSO9zugcNSVX1PmlxTwLHAQ0BFYAzzqVyAishfw\nFnCDqv4RvM3v8xYitpQ4b6q6U1U7Ai1xpf22fsQRSvnYRKQdcAcuxiOBfYDbkx2XiJwBrFPVmcl4\nv3RPEKuBVkHLLb11KUNVV3t/1wHjcf9RUsmvInIAgPd3nc/xlFLVX73/yCXAKHw6dyJSG3cBzlfV\n/3irU+K8hYotVc5bgKpuAj4BjgEai8ge3ibf/78GxdbTq7JTVd0OvIQ/560r0FtEluOqzHsAT5Kg\n85buCWIGcIjXwl8H6AtM9DmmUiLSQEQaBp4DpwDzIh+VdBOBy73nlwNv+xjLLgIXYM85+HDuvPrf\nfwELVfWxoE2+n7dwsaXIeWsuIo295/WAk3FtJJ8A53m7+XXeQsX2Q1DCF1wdf9LPm6reoaotVTUL\ndz37WFX7kajz5ndrfKIfwGm43hs/AUP9jqdcbAfielbNAeb7HR/wGq7KYQeuHvMqXP3mVGAxMAXY\nJ4ViewX4HpiLuyAf4ENc3XDVR3OB2d7jtFQ4bxFiS4XzlgvM8mKYB/zTW38g8C2wBHgD2DOFYvvY\nO2/zgDF4PZ38egAnUNaLKSHnzYbaMMYYE1K6VzEZY4ypIksQxhhjQrIEYYwxJiRLEMYYY0KyBGGM\nMSYkSxDGVEBEdgaN4Dlb4jgqsIhkBY9Qa0wq2aPiXYyp8bapG3bBmBrFShDGVJG4uTweEjefx7ci\ncrC3PktEPvYGdZsqIq299fuJyHhvnoE5InKs91IZIjLKm3vgQ+/uXUTkOm8uh7kiMtanj2lqMEsQ\nxlSsXrkqpguDtv2uqu2Bp3GjbAL8LzBaVXOBfOApb/1TwGeq2gE3t8V8b/0hwDOqmgNsAvp464cA\nR3ivMyhRH86YcOxOamMqICJbVHWvEOuXAz1Udak3KN5aVW0qIr/hhq/Y4a1fo6rNRKQQaKlusLfA\na2ThhpM+xFu+HaitqveJyAfAFmACMEHL5igwJimsBGFMbDTM88rYHvR8J2Vtg6cDz+BKGzOCRus0\nJiksQRgTmwuD/n7lPf8SN9ImQD9gmvd8KnA1lE5I0yjci4pILaCVqn6Cm3egEbBbKcaYRLJfJMZU\nrJ43u1jAB6oa6OraRETm4koBF3nrrgVeEpFbgULgCm/99cBIEbkKV1K4GjdCbSgZwBgviQjwlLq5\nCYxJGmuDMKaKvDaIPFX9ze9YjEkEq2IyxhgTkpUgjDHGhGQlCGOMMSFZgjDGGBOSJQhjjDEhWYIw\nxhgTkiUIY4wxIf1/tXunnibDPjwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M-bZ5SCHiIMl"
      },
      "source": [
        "### Adding another hidden layer to the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZbZ6UBDfbjea"
      },
      "source": [
        "In model3, we only add another dense layer to see if that improves the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vw0le1YjDdCa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "4315b21f-5a92-4974-e9ce-d482220b17bb"
      },
      "source": [
        "# put your code here\n",
        "wordToIndex, indexToWord, wordToGlove = readGloveFile('./glove.6B.50d.txt')\n",
        "model3 = Sequential()\n",
        "model3.add(createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, False))\n",
        "model3.add(GlobalAveragePooling1DMasked())\n",
        "model3.add(Dense(50, activation='relu'))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# model3 summary\n",
        "model3.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 50)          20000050  \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_mas (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 20,002,651\n",
            "Trainable params: 2,601\n",
            "Non-trainable params: 20,000,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSWNXdHRaOuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0549cf32-60b0-4af7-cc35-e963e3880576"
      },
      "source": [
        "X_val = np.array(X_train_enc[:10000])\n",
        "partial_X_train = np.array(X_train_enc[10000:])\n",
        "\n",
        "y_val = np.array(y_train[:10000])\n",
        "partial_y_train = np.array(y_train[10000:])\n",
        "\n",
        "history3 = model3.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 67us/step - loss: 0.6921 - acc: 0.5213 - val_loss: 0.6891 - val_acc: 0.5684\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6867 - acc: 0.5699 - val_loss: 0.6857 - val_acc: 0.5704\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6830 - acc: 0.5722 - val_loss: 0.6825 - val_acc: 0.5739\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6799 - acc: 0.5769 - val_loss: 0.6799 - val_acc: 0.5769\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6768 - acc: 0.5848 - val_loss: 0.6778 - val_acc: 0.5817\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6742 - acc: 0.5881 - val_loss: 0.6759 - val_acc: 0.5851\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6721 - acc: 0.5940 - val_loss: 0.6739 - val_acc: 0.5909\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6699 - acc: 0.5959 - val_loss: 0.6731 - val_acc: 0.5827\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6684 - acc: 0.5979 - val_loss: 0.6703 - val_acc: 0.5964\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6661 - acc: 0.6013 - val_loss: 0.6694 - val_acc: 0.5935\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6641 - acc: 0.6031 - val_loss: 0.6675 - val_acc: 0.5996\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6632 - acc: 0.6023 - val_loss: 0.6664 - val_acc: 0.5995\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6615 - acc: 0.6082 - val_loss: 0.6653 - val_acc: 0.6011\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6602 - acc: 0.6102 - val_loss: 0.6640 - val_acc: 0.6015\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6586 - acc: 0.6069 - val_loss: 0.6637 - val_acc: 0.6019\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6579 - acc: 0.6130 - val_loss: 0.6624 - val_acc: 0.6018\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6567 - acc: 0.6135 - val_loss: 0.6621 - val_acc: 0.6033\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6554 - acc: 0.6181 - val_loss: 0.6624 - val_acc: 0.6007\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6568 - acc: 0.6123 - val_loss: 0.6634 - val_acc: 0.6002\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6545 - acc: 0.6180 - val_loss: 0.6615 - val_acc: 0.6010\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6536 - acc: 0.6192 - val_loss: 0.6600 - val_acc: 0.6044\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6534 - acc: 0.6198 - val_loss: 0.6621 - val_acc: 0.6003\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6523 - acc: 0.6193 - val_loss: 0.6590 - val_acc: 0.6046\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6513 - acc: 0.6233 - val_loss: 0.6607 - val_acc: 0.6014\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6514 - acc: 0.6226 - val_loss: 0.6584 - val_acc: 0.6039\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6504 - acc: 0.6235 - val_loss: 0.6582 - val_acc: 0.6043\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6503 - acc: 0.6201 - val_loss: 0.6581 - val_acc: 0.6069\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6499 - acc: 0.6239 - val_loss: 0.6581 - val_acc: 0.6067\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6504 - acc: 0.6218 - val_loss: 0.6591 - val_acc: 0.6059\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6494 - acc: 0.6235 - val_loss: 0.6584 - val_acc: 0.6058\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6488 - acc: 0.6225 - val_loss: 0.6567 - val_acc: 0.6070\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6482 - acc: 0.6251 - val_loss: 0.6565 - val_acc: 0.6095\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 0s 10us/step - loss: 0.6476 - acc: 0.6264 - val_loss: 0.6573 - val_acc: 0.6069\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6479 - acc: 0.6273 - val_loss: 0.6562 - val_acc: 0.6076\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6472 - acc: 0.6258 - val_loss: 0.6557 - val_acc: 0.6075\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6469 - acc: 0.6275 - val_loss: 0.6560 - val_acc: 0.6085\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6468 - acc: 0.6278 - val_loss: 0.6555 - val_acc: 0.6104\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6465 - acc: 0.6267 - val_loss: 0.6559 - val_acc: 0.6108\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6463 - acc: 0.6268 - val_loss: 0.6561 - val_acc: 0.6099\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6454 - acc: 0.6300 - val_loss: 0.6547 - val_acc: 0.6109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QtsdVeW7UgCu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3ba0a7c1-d89b-47bf-e5aa-8c56f264e38e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history3.history\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKUGIiEis/wdGKa0BaU8XsAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kx--Ytk3ZbLo"
      },
      "source": [
        "The accuracy of model3 with an additional layer is 85%. Adding more layers can help you to extract more features. But we can do that upto a certain extent. After some point, instead of extracting features, we tend to overfit the data. Overfitting can lead to errors in some or the other form like false positives. It is not easy to choose the number of units in a hidden layer or the number of hidden layers in a neural network. For many applications, one hidden layer is enough. As a general rule, the number of units in that hidden layer is between the number of inputs and the number of outputs.\n",
        " The best way to decide on the number of units and hidden layers is to try various parameters. Train several neural networks with different numbers of hidden layers and neurons, and monitor the performance of them. You will have to experiment using a series of different architectures. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gn2GSV4ioyO2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XYC6DykEox2w",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GsCJ01StlgCx"
      },
      "source": [
        "This tutorial is substantially based on this document:\n",
        "https://www.tensorflow.org/tutorials/keras/basic_text_classification\n",
        "\n",
        "To read more about Sequential APIs you can go to: https://keras.io/getting-started/sequential-model-guide/\n",
        "\n",
        "The one-hot word vector layer is taken from:\n",
        "https://fdalvi.github.io/blog/2018-04-07-keras-sequential-onehot/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jL0UovfaE9GE",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}